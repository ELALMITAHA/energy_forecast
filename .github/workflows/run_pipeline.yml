name: Daily MLOps Forecast Pipeline

on:
  schedule:
    - cron: "0 1 * * *"   # Tous les jours Ã  01:00 UTC
  workflow_dispatch:

jobs:
  run_pipeline:
    runs-on: ubuntu-latest

    steps:
      # 1 Checkout repository
      - name: Checkout repository
        uses: actions/checkout@v4

      # 2 Setup Python
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      # 3 Install full Python dependencies
      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      # 4 Install HuggingFace CLI
      - name: Install HuggingFace CLI
        run: |
          curl -LsSf https://hf.co/cli/install.sh | bash

      # 5 Prepare artifact directories
      - name: Prepare artifact directories
        run: |
          mkdir -p /tmp/data/raw
          mkdir -p /tmp/data/processed
          mkdir -p /tmp/artifacts/data_quality
          mkdir -p /tmp/artifacts/forecasts
          mkdir -p /tmp/artifacts/models
          mkdir -p /tmp/artifacts/logs

      # 6 Run Dagster Job
      - name: Run Dagster Job
        env:
          RAW_DIR: /tmp/data/raw
          PROCESSED_DIR: /tmp/data/processed
          DATA_QUALITY_DIR: /tmp/artifacts/data_quality
          FORECAST_DIR: /tmp/artifacts/forecasts
          MODELS_DIR: /tmp/artifacts/models
          LOGS_DIR: /tmp/artifacts/logs
        run: |
          dagster job execute \
            -f src/pipeline/run_full_pipeline_dagster.py \
            -j full_pipeline \
            --config executor_config.yaml

      # 7 Copy generated artifacts to upload folder
      - name: Copy generated artifacts
        run: |
          mkdir -p data-artifact/models
          mkdir -p data-artifact/forecasts
          mkdir -p data-artifact/data_quality
          cp /tmp/artifacts/models/*.pkl data-artifact/models/ || true
          cp /tmp/artifacts/forecasts/*.parquet data-artifact/forecasts/ || true
          cp /tmp/artifacts/data_quality/*.json data-artifact/data_quality/ || true
          cp /tmp/artifacts/logs/*.log data-artifact/logs/ || true

      # 8 Upload artifacts to HuggingFace dataset (overwrite)
      - name: Upload artifacts to HuggingFace dataset
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          hf upload tahaelalmi/energy-forecast-artifacts \
            data-artifact/models \
            data-artifact/forecasts \
            data-artifact/data_quality \
            --repo-type dataset \
            --token $HF_TOKEN

      # 9 Upload pipeline logs as GitHub Action artifact (optional)
      - name: Upload pipeline log
        uses: actions/upload-artifact@v4
        with:
          name: pipeline-log
          path: data-artifact/logs/







